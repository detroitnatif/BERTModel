{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18216d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "import random\n",
    "import random\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "import pathlib\n",
    "import sklearn\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import glob\n",
    "import functools\n",
    "import utils\n",
    "\n",
    "TOKENIZERS_PARALLELISM=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29265aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ACCESSORY',\n",
       " 1: 'BOOT',\n",
       " 2: 'CELLULAR_PHONE_CASE',\n",
       " 3: 'CHAIR',\n",
       " 4: 'EARRING',\n",
       " 5: 'FINEEARRING',\n",
       " 6: 'FINENECKLACEBRACELETANKLET',\n",
       " 7: 'FINERING',\n",
       " 8: 'GROCERY',\n",
       " 9: 'HANDBAG',\n",
       " 10: 'HARDWARE_HANDLE',\n",
       " 11: 'HAT',\n",
       " 12: 'HEALTH_PERSONAL_CARE',\n",
       " 13: 'HOME',\n",
       " 14: 'HOME_BED_AND_BATH',\n",
       " 15: 'HOME_FURNITURE_AND_DECOR',\n",
       " 16: 'JANITORIAL_SUPPLY',\n",
       " 17: 'KITCHEN',\n",
       " 18: 'LAMP',\n",
       " 19: 'LIGHT_BULB',\n",
       " 20: 'LIGHT_FIXTURE',\n",
       " 21: 'OFFICE_PRODUCTS',\n",
       " 22: 'OUTDOOR_LIVING',\n",
       " 23: 'PET_SUPPLIES',\n",
       " 24: 'RUG',\n",
       " 25: 'SANDAL',\n",
       " 26: 'SHOES',\n",
       " 27: 'SOFA',\n",
       " 28: 'SPORTING_GOODS',\n",
       " 29: 'TABLE',\n",
       " 30: 'WALL_ART'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "dataset_path = '/Users/tylerklimas/Desktop/BERTModel/dataset_processed'\n",
    "dataset_raw = datasets.load_from_disk(dataset_path)\n",
    "\n",
    "labels = dataset_raw['train'].features['label'].names\n",
    "\n",
    "\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "for idx, ele in enumerate(labels):\n",
    "    label2id[ele] = idx\n",
    "    id2label[idx] = ele\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9919ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"distilbert-base-uncased\"\n",
    "model_dir = '/Users/tylerklimas/Desktop/BERTModel/BERTModelArchive'\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_dir, return_dict=False)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3345dafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand', 'item_id', 'item_name', 'main_image_id', 'node'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = set(dataset_raw['train'].column_names) - set(['text', 'label'])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef20c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset_raw.map(tokenize_function, batched=True, remove_columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76147774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tokenized_datasets['train'].num_rows\n",
    "subset = 50 # JUST FOR INFERENCE PURPOSE\n",
    "\n",
    "test_dataset = tokenized_datasets['test'].shuffle(seed=22).select(range(subset))\n",
    "test_dataset.set_format(type='torch')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b376605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:13<00:00,  6.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "utils.prediction_batch(model, test_dataset)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d18a5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model_int8 = torch.quantization.quantize_dynamic(\n",
    "                       model,\n",
    "                       {torch.nn.Linear},\n",
    "                       dtype = torch.qint8)\n",
    "# quantized_model_int8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab29a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB):  267.942302\n",
      "Size (MB):  138.729314\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_size_model(model):\n",
    "    torch.save(model.state_dict(), 'temp.p')\n",
    "    print('Size (MB): ', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "    \n",
    "print_size_model(model)\n",
    "print_size_model(quantized_model_int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72ccfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"distilbert-base-uncased\"\n",
    "script_tokenizer = transformers.AutoTokenizer.from_pretrained(model_dir, torchscript=True)\n",
    "script_model = transformers.AutoModelForSequenceClassification.from_pretrained(model_dir,\n",
    "                                                                        num_labels = len(labels),\n",
    "                                                                        label2id=label2id,\n",
    "                                                                        id2label=id2label,\n",
    "                                                                        torchscript=True)                                               \n",
    "                                                                               \n",
    "                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f9b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:246: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  mask, torch.tensor(torch.finfo(scores.dtype).min)\n"
     ]
    }
   ],
   "source": [
    "text = 'mens dress shoes'\n",
    "\n",
    "res = script_tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', truncation=True)\n",
    "\n",
    "text_tokens = res['input_ids'].to(device)\n",
    "text_attentions = res['attention_mask'].to(device)\n",
    "\n",
    "dummy_input = [text_tokens, text_attentions]\n",
    "\n",
    "script_model = script_model.to(device)\n",
    "\n",
    "traced_model = torch.jit.trace(script_model, dummy_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ea8664c-9c08-4757-ad0b-d02e19be6e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26, 1, 25, 0, 13]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'26'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraced_model\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_tokens\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_attentions\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2label_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/BERTModel/utils.py:56\u001b[0m, in \u001b[0;36mprediction\u001b[0;34m(model, tokens_tensor, masks_tensors, id2label_str, topk)\u001b[0m\n\u001b[1;32m     54\u001b[0m classes \u001b[38;5;241m=\u001b[39m classes\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(classes)\n\u001b[0;32m---> 56\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mmap_class_to_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2label_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ts/utils/util.py:120\u001b[0m, in \u001b[0;36mmap_class_to_label\u001b[0;34m(probs, mapping, lbl_classes)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lbl_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     lbl_classes \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(probs[\u001b[38;5;241m0\u001b[39m])), \u001b[38;5;28mlen\u001b[39m(probs))\n\u001b[0;32m--> 120\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     {\n\u001b[1;32m    122\u001b[0m         (mapping[\u001b[38;5;28mstr\u001b[39m(lbl_class)] \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(lbl_class)): prob\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lbl_class, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mrow)\n\u001b[1;32m    124\u001b[0m     }\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lbl_classes, probs)\n\u001b[1;32m    126\u001b[0m ]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ts/utils/util.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lbl_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     lbl_classes \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(probs[\u001b[38;5;241m0\u001b[39m])), \u001b[38;5;28mlen\u001b[39m(probs))\n\u001b[1;32m    120\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 121\u001b[0m     {\n\u001b[1;32m    122\u001b[0m         (mapping[\u001b[38;5;28mstr\u001b[39m(lbl_class)] \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(lbl_class)): prob\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lbl_class, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mrow)\n\u001b[1;32m    124\u001b[0m     }\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lbl_classes, probs)\n\u001b[1;32m    126\u001b[0m ]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ts/utils/util.py:122\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lbl_classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     lbl_classes \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(probs[\u001b[38;5;241m0\u001b[39m])), \u001b[38;5;28mlen\u001b[39m(probs))\n\u001b[1;32m    120\u001b[0m results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    121\u001b[0m     {\n\u001b[0;32m--> 122\u001b[0m         (\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlbl_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(lbl_class)): prob\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lbl_class, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mrow)\n\u001b[1;32m    124\u001b[0m     }\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lbl_classes, probs)\n\u001b[1;32m    126\u001b[0m ]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[0;31mKeyError\u001b[0m: '26'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "utils.prediction( model=traced_model\n",
    "                 , tokens_tensor=text_tokens\n",
    "                 , masks_tensors=text_attentions \n",
    "                 , id2label_str=id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed8bba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/Users/tylerklimas/Desktop/BERTModel/BERTModelArchive'\n",
    "model.save_pretrained('/Users/tylerklimas/Desktop/BERTModel/BERTModelArchive')\n",
    "tokenizer.save_pretrained('/Users/tylerklimas/Desktop/BERTModel/TBERTModelArchive')\n",
    "torch.save(model.state_dict(), '/Users/tylerklimas/Desktop/BERTModel/TrainedModels/model_weights.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5944ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_config = {\n",
    "    'model_name':\"pt-original\",\n",
    "    \"do_lower_case\": tokenizer.do_lower_case,\n",
    "    \"num_labels\":len(id2label),\n",
    "    'save_mode':\"original\",\n",
    "    'max_length': tokenizer.model_max_length,\n",
    "    'captum_explanation': True,\n",
    "    \"base_model\": 'distilbert-base-uncased',\n",
    "    'top_k': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f483b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f'{model_dir}/setup_config.json', 'w') as f:\n",
    "    json.dump(setup_config,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d4ddc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_config_trace = {**setup_config}\n",
    "setup_config_trace['model_name'] = 'pt-jit'\n",
    "setup_config_trace['capture_explanation'] = False\n",
    "setup_config_trace['save_model'] = 'jit'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6b9f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{model_dir}/setup_config.json', 'w') as f:\n",
    "    json.dump(setup_config_trace,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea5efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
